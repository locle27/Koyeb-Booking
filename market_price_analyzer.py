"""
Market Price Analyzer - Ph√¢n t√≠ch gi√° th·ªã tr∆∞·ªùng t·ª´ Booking.com
S·ª≠ d·ª•ng crawl4ai ƒë·ªÉ thu th·∫≠p d·ªØ li·ªáu gi√° c·∫£ t·ª´ c√°c n·ªÅn t·∫£ng booking
"""

import asyncio
import json
import re
import statistics
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import pandas as pd

try:
    from crawl4ai import AsyncWebCrawler
    CRAWL4AI_AVAILABLE = True
except ImportError:
    try:
        from crawl4ai import WebCrawler, BrowserConfig, CrawlerRunConfig
        CRAWL4AI_AVAILABLE = True
    except ImportError:
        CRAWL4AI_AVAILABLE = False
        print("WARNING: crawl4ai not available - Market Price Analyzer will use fallback mode")

try:
    import google.generativeai as genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False

import requests
from bs4 import BeautifulSoup
import time
import random


class MarketPriceAnalyzer:
    """Ph√¢n t√≠ch gi√° th·ªã tr∆∞·ªùng t·ª´ c√°c platform booking"""
    
    def __init__(self, google_api_key: Optional[str] = None):
        self.google_api_key = google_api_key
        self.crawler = None
        self.results_cache = {}
        
        if GENAI_AVAILABLE and google_api_key:
            genai.configure(api_key=google_api_key)
        
    async def initialize_crawler(self):
        """Kh·ªüi t·∫°o crawler v·ªõi c·∫•u h√¨nh t·ªëi ∆∞u"""
        if not CRAWL4AI_AVAILABLE:
            print("ERROR: crawl4ai kh√¥ng kh·∫£ d·ª•ng")
            return False
            
        try:
            # S·ª≠ d·ª•ng AsyncWebCrawler cho version m·ªõi
            self.crawler = AsyncWebCrawler(
                headless=True,
                browser_type="chromium",
                verbose=True
            )
            await self.crawler.astart()
            print("SUCCESS: Crawler kh·ªüi t·∫°o th√†nh c√¥ng")
            return True
            
        except Exception as e:
            print(f"ERROR: L·ªói kh·ªüi t·∫°o crawler: {e}")
            return False
    
    async def crawl_booking_prices(self, booking_url: str, max_properties: int = 15) -> Dict:
        """
        Crawl gi√° t·ª´ Booking.com v·ªõi URL c·ª• th·ªÉ
        
        Args:
            booking_url: URL t√¨m ki·∫øm Booking.com
            max_properties: S·ªë l∆∞·ª£ng property t·ªëi ƒëa c·∫ßn crawl
            
        Returns:
            Dict ch·ª©a th√¥ng tin properties v√† ph√¢n t√≠ch gi√°
        """
        print(f"üîç B·∫Øt ƒë·∫ßu crawl gi√° t·ª´ Booking.com (max: {max_properties} properties)")
        
        if not self.crawler:
            success = await self.initialize_crawler()
            if not success:
                return await self._fallback_crawl_booking(booking_url, max_properties)
        
        try:
            # Th·ª±c hi·ªán crawl v·ªõi API m·ªõi
            result = await self.crawler.arun(
                url=booking_url,
                word_count_threshold=50,
                page_timeout=30000,
                delay_before_return_html=3.0
            )
            
            if result.success:
                print("SUCCESS: Crawl th√†nh c√¥ng, ƒëang x·ª≠ l√Ω d·ªØ li·ªáu...")
                return await self._process_crawl_result(result, max_properties)
            else:
                print(f"ERROR: Crawl th·∫•t b·∫°i: {result.error}")
                return await self._fallback_crawl_booking(booking_url, max_properties)
                
        except Exception as e:
            print(f"ERROR: L·ªói trong qu√° tr√¨nh crawl: {e}")
            return await self._fallback_crawl_booking(booking_url, max_properties)
    
    async def _process_crawl_result(self, result, max_properties: int) -> Dict:
        """X·ª≠ l√Ω k·∫øt qu·∫£ crawl v√† tr√≠ch xu·∫•t d·ªØ li·ªáu gi√°"""
        try:
            # Parse HTML tr·ª±c ti·∫øp v√¨ kh√¥ng d√πng LLM extraction
            properties = await self._parse_html_fallback(result.html)
            
            # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng properties
            properties = properties[:max_properties]
            
            # L√†m s·∫°ch v√† ph√¢n t√≠ch d·ªØ li·ªáu
            cleaned_properties = self._clean_property_data(properties)
            analysis = self._analyze_prices(cleaned_properties)
            
            return {
                'success': True,
                'total_properties': len(cleaned_properties),
                'properties': cleaned_properties,
                'price_analysis': analysis,
                'crawl_timestamp': datetime.now().isoformat(),
                'source_url': result.url if hasattr(result, 'url') else 'booking.com'
            }
            
        except Exception as e:
            print(f"ERROR: L·ªói x·ª≠ l√Ω k·∫øt qu·∫£: {e}")
            return {
                'success': False,
                'error': str(e),
                'properties': [],
                'price_analysis': {}
            }
    
    async def _parse_html_fallback(self, html_content: str) -> List[Dict]:
        """Fallback parser s·ª≠ d·ª•ng BeautifulSoup khi LLM extraction fail"""
        print("üîÑ S·ª≠ d·ª•ng HTML parser fallback...")
        
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            properties = []
            
            # T√¨m c√°c property containers (c·∫•u tr√∫c c√≥ th·ªÉ thay ƒë·ªïi)
            property_selectors = [
                '[data-testid="property-card"]',
                '.sr_property_block',
                '.c-sr-property-block',
                '[data-testid="property-card-container"]'
            ]
            
            property_elements = []
            for selector in property_selectors:
                elements = soup.select(selector)
                if elements:
                    property_elements = elements
                    print(f"‚úÖ T√¨m th·∫•y {len(elements)} properties v·ªõi selector: {selector}")
                    break
            
            for elem in property_elements[:15]:  # Gi·ªõi h·∫°n 15 properties
                try:
                    property_data = self._extract_property_from_element(elem)
                    if property_data:
                        properties.append(property_data)
                except Exception as e:
                    print(f"‚ö†Ô∏è L·ªói parse property: {e}")
                    continue
            
            print(f"‚úÖ ƒê√£ parse {len(properties)} properties th√†nh c√¥ng")
            return properties
            
        except Exception as e:
            print(f"‚ùå L·ªói HTML parser: {e}")
            return []
    
    def _extract_property_from_element(self, elem) -> Optional[Dict]:
        """Tr√≠ch xu·∫•t th√¥ng tin property t·ª´ HTML element"""
        try:
            # T√™n property
            name_selectors = [
                '[data-testid="title"]',
                '.sr-hotel__name',
                '.fcab3ed991.a23c043802',
                'h3',
                '.property-card__name'
            ]
            name = self._find_text_by_selectors(elem, name_selectors, "Unknown Property")
            
            # Gi√°
            price_selectors = [
                '[data-testid="price-and-discounted-price"]',
                '.prco-valign-middle-helper',
                '.bui-price-display__value',
                '.sr-hotel__price',
                '[data-testid="price"]'
            ]
            price_text = self._find_text_by_selectors(elem, price_selectors, "0")
            
            # Rating
            rating_selectors = [
                '[data-testid="review-score"]',
                '.bui-review-score__badge',
                '.sr-hotel__review-score'
            ]
            rating = self._find_text_by_selectors(elem, rating_selectors, "N/A")
            
            # Location (c√≥ th·ªÉ kh√¥ng c√≥)
            location_selectors = [
                '[data-testid="address"]',
                '.sr-hotel__address',
                '.property-card__address'
            ]
            location = self._find_text_by_selectors(elem, location_selectors, "")
            
            return {
                'name': name.strip(),
                'price': price_text.strip(),
                'rating': rating.strip(),
                'location': location.strip(),
                'room_type': 'Standard'  # Default
            }
            
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói extract property: {e}")
            return None
    
    def _find_text_by_selectors(self, parent_elem, selectors: List[str], default: str = "") -> str:
        """T√¨m text b·∫±ng danh s√°ch selectors"""
        for selector in selectors:
            try:
                elem = parent_elem.select_one(selector)
                if elem and elem.get_text(strip=True):
                    return elem.get_text(strip=True)
            except:
                continue
        return default
    
    def _clean_property_data(self, properties: List[Dict]) -> List[Dict]:
        """L√†m s·∫°ch v√† chu·∫©n h√≥a d·ªØ li·ªáu property"""
        cleaned = []
        
        for prop in properties:
            try:
                # L√†m s·∫°ch gi√°
                price_vnd = self._extract_price_vnd(prop.get('price', ''))
                
                # Ch·ªâ gi·ªØ l·∫°i properties c√≥ gi√° h·ª£p l·ªá
                if price_vnd > 0:
                    cleaned_prop = {
                        'name': prop.get('name', 'Unknown')[:100],  # Gi·ªõi h·∫°n ƒë·ªô d√†i
                        'price_vnd': price_vnd,
                        'price_display': f"{price_vnd:,.0f}‚Ç´",
                        'rating': self._clean_rating(prop.get('rating', '')),
                        'location': prop.get('location', '')[:100],
                        'room_type': prop.get('room_type', 'Standard')
                    }
                    cleaned.append(cleaned_prop)
                    
            except Exception as e:
                print(f"‚ö†Ô∏è L·ªói clean property: {e}")
                continue
        
        print(f"‚úÖ ƒê√£ l√†m s·∫°ch {len(cleaned)} properties")
        return cleaned
    
    def _extract_price_vnd(self, price_text: str) -> float:
        """Tr√≠ch xu·∫•t v√† chuy·ªÉn ƒë·ªïi gi√° v·ªÅ VND"""
        try:
            # Lo·∫°i b·ªè c√°c k√Ω t·ª± kh√¥ng c·∫ßn thi·∫øt
            price_clean = re.sub(r'[^\d.,]', '', price_text)
            
            # T√¨m s·ªë
            numbers = re.findall(r'[\d.,]+', price_clean)
            if not numbers:
                return 0
            
            # L·∫•y s·ªë l·ªõn nh·∫•t (th∆∞·ªùng l√† gi√° ch√≠nh)
            max_number = max(numbers, key=len)
            
            # X·ª≠ l√Ω d·∫•u ph·∫©y v√† ch·∫•m
            if ',' in max_number and '.' in max_number:
                # Format: 1,234.56 ho·∫∑c 1.234,56
                if max_number.rfind(',') > max_number.rfind('.'):
                    # Format: 1.234,56 (European)
                    max_number = max_number.replace('.', '').replace(',', '.')
                else:
                    # Format: 1,234.56 (US)
                    max_number = max_number.replace(',', '')
            elif ',' in max_number:
                # Ch·ªâ c√≥ d·∫•u ph·∫©y - c√≥ th·ªÉ l√† separator ho·∫∑c decimal
                if len(max_number.split(',')[-1]) <= 2:
                    # C√≥ th·ªÉ l√† decimal
                    max_number = max_number.replace(',', '.')
                else:
                    # L√† separator
                    max_number = max_number.replace(',', '')
            
            price_float = float(max_number)
            
            # Detect currency v√† convert v·ªÅ VND
            if 'USD' in price_text.upper() or '$' in price_text:
                price_float *= 24000  # USD to VND approximation
            elif 'EUR' in price_text.upper() or '‚Ç¨' in price_text:
                price_float *= 26000  # EUR to VND approximation
            elif price_float < 1000:  # C√≥ th·ªÉ l√† USD
                price_float *= 24000
            
            return price_float
            
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói parse gi√° '{price_text}': {e}")
            return 0
    
    def _clean_rating(self, rating_text: str) -> str:
        """L√†m s·∫°ch rating"""
        try:
            # T√¨m s·ªë rating
            rating_match = re.search(r'(\d+\.?\d*)', rating_text)
            if rating_match:
                return rating_match.group(1)
            return "N/A"
        except:
            return "N/A"
    
    def _analyze_prices(self, properties: List[Dict]) -> Dict:
        """Ph√¢n t√≠ch gi√° c·∫£ v√† t·∫°o insights"""
        if not properties:
            return {}
        
        prices = [prop['price_vnd'] for prop in properties if prop['price_vnd'] > 0]
        
        if not prices:
            return {}
        
        analysis = {
            'total_properties': len(properties),
            'price_count': len(prices),
            'min_price': min(prices),
            'max_price': max(prices),
            'avg_price': statistics.mean(prices),
            'median_price': statistics.median(prices),
            'price_std': statistics.stdev(prices) if len(prices) > 1 else 0,
        }
        
        # Ph√¢n lo·∫°i gi√°
        analysis['price_ranges'] = self._categorize_prices(prices)
        
        # Insights
        analysis['insights'] = self._generate_insights(analysis, properties)
        
        return analysis
    
    def _categorize_prices(self, prices: List[float]) -> Dict:
        """Ph√¢n lo·∫°i gi√° theo c√°c t·∫ßng"""
        if not prices:
            return {}
        
        # ƒê·ªãnh nghƒ©a c√°c t·∫ßng gi√°
        ranges = {
            'budget': (0, 500000),           # D∆∞·ªõi 500k
            'mid_range': (500000, 1000000),  # 500k - 1M
            'upscale': (1000000, 2000000),   # 1M - 2M
            'luxury': (2000000, float('inf')) # Tr√™n 2M
        }
        
        categorized = {}
        for category, (min_price, max_price) in ranges.items():
            count = len([p for p in prices if min_price <= p < max_price])
            percentage = (count / len(prices)) * 100
            categorized[category] = {
                'count': count,
                'percentage': round(percentage, 1),
                'range': f"{min_price/1000:.0f}k - {max_price/1000:.0f}k" if max_price != float('inf') else f">{min_price/1000:.0f}k"
            }
        
        return categorized
    
    def _generate_insights(self, analysis: Dict, properties: List[Dict]) -> List[str]:
        """T·∫°o insights t·ª´ ph√¢n t√≠ch gi√°"""
        insights = []
        
        avg_price = analysis['avg_price']
        median_price = analysis['median_price']
        
        # Insight v·ªÅ gi√° trung b√¨nh
        insights.append(f"üí∞ Gi√° trung b√¨nh: {avg_price:,.0f}‚Ç´/ƒë√™m")
        insights.append(f"üìä Gi√° trung v·ªã: {median_price:,.0f}‚Ç´/ƒë√™m")
        
        # So s√°nh gi√°
        if avg_price > median_price * 1.2:
            insights.append("üìà C√≥ m·ªôt s·ªë property gi√° cao k√©o trung b√¨nh l√™n")
        elif avg_price < median_price * 0.8:
            insights.append("üìâ Ph·∫ßn l·ªõn property c√≥ gi√° th·∫•p, √≠t property premium")
        
        # Ph√¢n t√≠ch theo t·∫ßng gi√°
        ranges = analysis.get('price_ranges', {})
        if ranges:
            dominant_range = max(ranges.items(), key=lambda x: x[1]['count'])
            insights.append(f"üéØ T·∫ßng gi√° ph·ªï bi·∫øn nh·∫•t: {dominant_range[0]} ({dominant_range[1]['percentage']}%)")
        
        # Insight v·ªÅ ƒë·ªô bi·∫øn ƒë·ªông
        if analysis.get('price_std', 0) > avg_price * 0.5:
            insights.append("‚ö° Gi√° c√≥ ƒë·ªô bi·∫øn ƒë·ªông cao - th·ªã tr∆∞·ªùng ƒëa d·∫°ng")
        else:
            insights.append("üéØ Gi√° t∆∞∆°ng ƒë·ªëi ·ªïn ƒë·ªãnh - th·ªã tr∆∞·ªùng ƒë·ªìng nh·∫•t")
        
        return insights

    async def _fallback_crawl_booking(self, booking_url: str, max_properties: int) -> Dict:
        """Fallback method s·ª≠ d·ª•ng requests + BeautifulSoup"""
        print("üîÑ S·ª≠ d·ª•ng fallback crawl method...")
        
        try:
            # Headers ƒë·ªÉ tr√°nh b·ªã block
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'vi-VN,vi;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
            }
            
            # Random delay ƒë·ªÉ tr√°nh rate limiting
            await asyncio.sleep(random.uniform(1, 3))
            
            response = requests.get(booking_url, headers=headers, timeout=30)
            response.raise_for_status()
            
            # Parse HTML
            properties = await self._parse_html_fallback(response.text)
            
            # L√†m s·∫°ch v√† ph√¢n t√≠ch
            cleaned_properties = self._clean_property_data(properties)
            analysis = self._analyze_prices(cleaned_properties)
            
            return {
                'success': True,
                'total_properties': len(cleaned_properties),
                'properties': cleaned_properties[:max_properties],
                'price_analysis': analysis,
                'crawl_timestamp': datetime.now().isoformat(),
                'source_url': booking_url,
                'method': 'fallback'
            }
            
        except Exception as e:
            print(f"‚ùå Fallback crawl failed: {e}")
            return {
                'success': False,
                'error': str(e),
                'properties': [],
                'price_analysis': {},
                'method': 'fallback'
            }
    
    async def cleanup(self):
        """D·ªçn d·∫πp resources"""
        if self.crawler:
            try:
                await self.crawler.aclose()
            except:
                pass

# Utility functions
async def analyze_market_prices(booking_url: str, google_api_key: Optional[str] = None, max_properties: int = 15) -> Dict:
    """
    H√†m ch√≠nh ƒë·ªÉ ph√¢n t√≠ch gi√° th·ªã tr∆∞·ªùng
    
    Args:
        booking_url: URL Booking.com ƒë·ªÉ crawl
        google_api_key: API key cho Gemini (optional)
        max_properties: S·ªë l∆∞·ª£ng property t·ªëi ƒëa
        
    Returns:
        Dict ch·ª©a k·∫øt qu·∫£ ph√¢n t√≠ch
    """
    analyzer = MarketPriceAnalyzer(google_api_key)
    
    try:
        result = await analyzer.crawl_booking_prices(booking_url, max_properties)
        return result
    finally:
        await analyzer.cleanup()

def format_price_analysis_for_display(analysis_result: Dict) -> Dict:
    """Format k·∫øt qu·∫£ ph√¢n t√≠ch ƒë·ªÉ hi·ªÉn th·ªã tr√™n frontend"""
    if not analysis_result.get('success'):
        return {
            'error': analysis_result.get('error', 'Unknown error'),
            'success': False
        }
    
    properties = analysis_result.get('properties', [])
    price_analysis = analysis_result.get('price_analysis', {})
    
    return {
        'success': True,
        'summary': {
            'total_found': len(properties),
            'avg_price': price_analysis.get('avg_price', 0),
            'min_price': price_analysis.get('min_price', 0),
            'max_price': price_analysis.get('max_price', 0),
            'median_price': price_analysis.get('median_price', 0),
        },
        'properties': properties,
        'insights': price_analysis.get('insights', []),
        'price_ranges': price_analysis.get('price_ranges', {}),
        'timestamp': analysis_result.get('crawl_timestamp'),
        'source_url': analysis_result.get('source_url')
    }
